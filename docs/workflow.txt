I'm pulling my personal data/pictures from Flickr using the following python scripts. The first is formatting a CSV with info:
flickr2csv.py {album id} {output name}.csv

import requests
import csv
import time
import argparse

# Add your API key and user ID
API_KEY = 'ENTER API KEY'  # Replace with your Flickr API key
USER_ID = 'ENTER USER ID'  # Replace with your Flickr User ID (e.g., '12345678@N00')

def get_photo_titles_tags_urls(api_key, user_id, photoset_id):
    url = 'https://api.flickr.com/services/rest/'
    params = {
        'method': 'flickr.photosets.getPhotos',
        'api_key': api_key,
        'photoset_id': photoset_id,
        'user_id': user_id,
        'format': 'json',
        'nojsoncallback': 1
    }

    try:
        response = requests.get(url, params=params, timeout=30)
        data = response.json()

        if 'photoset' not in data:
            print("Error fetching data:", data)
            return []

        photos = []
        for photo in data['photoset']['photo']:
            photo_id = photo['id']
            title = photo['title']
            tags = get_photo_tags(api_key, photo_id)
            # Fetch URL_O (direct image URL)
            photo_url = get_photo_url_o(api_key, photo_id)
            photos.append((photo_id, title, tags, photo_url))
        
        return photos
    except requests.exceptions.RequestException as e:
        print(f"Error fetching photoset: {e}")
        return []

def get_photo_tags(api_key, photo_id):
    url = 'https://api.flickr.com/services/rest/'
    params = {
        'method': 'flickr.photos.getInfo',
        'api_key': api_key,
        'photo_id': photo_id,
        'format': 'json',
        'nojsoncallback': 1
    }

    try:
        response = requests.get(url, params=params, timeout=30)
        data = response.json()

        if 'photo' in data:
            tags = [tag['_content'] for tag in data['photo']['tags']['tag']]
            return ", ".join(tags)
        else:
            return ""
    except requests.exceptions.RequestException as e:
        print(f"Error fetching tags for photo {photo_id}: {e}")
        return ""
    finally:
        time.sleep(1)  # Rate limit delay

def get_photo_url_o(api_key, photo_id):
    url = 'https://api.flickr.com/services/rest/'
    params = {
        'method': 'flickr.photos.getSizes',
        'api_key': api_key,
        'photo_id': photo_id,
        'format': 'json',
        'nojsoncallback': 1
    }

    try:
        response = requests.get(url, params=params, timeout=30)
        data = response.json()

        if 'sizes' in data:
            for size in data['sizes']['size']:
                if size['label'] == 'Original':  # Get the original image size
                    return size['source']
        else:
            return ''
    except requests.exceptions.RequestException as e:
        print(f"Error fetching original photo URL for {photo_id}: {e}")
        return ''
    finally:
        time.sleep(1)  # Rate limit delay

def process_photos(photos):
    processed_photos = []
    for photo_id, title, tags, raw_url in photos:
        # Split title into "Set" and "Player"
        title_parts = title.split(',')
        set_name = title_parts[0].strip() if len(title_parts) > 0 else ''
        player = title_parts[1].strip() if len(title_parts) > 1 else ''

        # Further processing of "Player" and "Set"
        if '/' in player:
            set_name += f" /{player.split('/')[-1].strip()}"
            player = player.split('/')[0].strip()

        player = player.replace('-', '/')
        tags = f"({tags.upper().replace(', ', '/')})"

        # Trim whitespace
        player = player.strip()
        set_name = set_name.strip()
        tags = tags.strip()
        processed_url = processed_url.strip()

        # Format BBCode URL
        bbcode_url = f'[URL="{processed_url}"] photo[/URL]'

        # Add raw URL column
        processed_photos.append((photo_id, player, set_name, tags, raw_url, bbcode_url))

    return processed_photos

def save_to_csv(photos, filename='flickr_titles_tags_urls.csv'):
    with open(filename, 'w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow(['Photo ID', 'Player', 'Set', 'Tags', 'Raw URL', 'Processed URL'])
        writer.writerows(photos)

def main():
    parser = argparse.ArgumentParser(description="Fetch Flickr photoset data.")
    parser.add_argument('photoset_id', help="The ID of the Flickr photoset.")
    parser.add_argument('output_file', help="The name of the output CSV file.")
    args = parser.parse_args()

    photos = get_photo_titles_tags_urls(API_KEY, USER_ID, args.photoset_id)
    if photos:
        print("Photo titles, tags, and URLs retrieved successfully.")
        processed_photos = process_photos(photos)
        save_to_csv(processed_photos, args.output_file)
        print(f"Saved {len(processed_photos)} records to '{args.output_file}'.")
    else:
        print("No photos found or error retrieving data.")

if __name__ == "__main__":
    main()






The second python script downloads all of the photos from an album where I just modify the album id and execute:
flickr_album_download.py



import flickrapi
import requests
import os
import time

# Replace with your API key and secret
api_key = 'ENTER API KEY'
api_secret = 'ENTER SECRET KEY'

# Create the flickr object
flickr = flickrapi.FlickrAPI(api_key, api_secret, format='parsed-json')

# Get the album ID (replace with the actual album ID)
album_id = '[B][COLOR="red"]enter album id here[/COLOR][/B]'

# Get photos from the album
photos = flickr.photosets.getPhotos(photoset_id=album_id, user_id='ENTER USER ID')

# Loop through each photo and download
for photo in photos['photoset']['photo']:
    photo_id = photo['id']
    
    # Get the available sizes of the photo
    sizes = flickr.photos.getSizes(photo_id=photo_id)
    
    # Get the URL of the medium size image (you can change 'medium' to any other size)
    url = next((size['source'] for size in sizes['sizes']['size'] if size['label'] == 'Large'), None)
    
    if url:
        # Use the photo ID as the filename (e.g., '1234567890.jpg')
        filename = f"{photo_id}.jpg"

        # Download the image
        response = requests.get(url)
        
        if response.status_code == 200:
            # Create a folder if it doesn't exist
            if not os.path.exists('downloaded_photos'):
                os.makedirs('downloaded_photos')

            # Save the image in the folder
            with open(os.path.join('downloaded_photos', filename), 'wb') as f:
                f.write(response.content)
            print(f"Downloaded: {filename}")
        else:
            print(f"Failed to download: {filename}")
        
        # Add a delay to avoid hitting Flickr's rate limit
        time.sleep(2)  # Wait for 2 seconds between requests to prevent rate limit issues
    else:
        print(f"No large size found for photo {photo_id}")
